{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.2480037576326914,
  "eval_steps": 500,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03757632691404415,
      "grad_norm": 0.5524381995201111,
      "learning_rate": 0.0001974937343358396,
      "loss": 2.4745,
      "step": 10
    },
    {
      "epoch": 0.0751526538280883,
      "grad_norm": 0.8712276220321655,
      "learning_rate": 0.00019498746867167922,
      "loss": 2.2042,
      "step": 20
    },
    {
      "epoch": 0.11272898074213246,
      "grad_norm": 0.9988397359848022,
      "learning_rate": 0.0001924812030075188,
      "loss": 2.1201,
      "step": 30
    },
    {
      "epoch": 0.1503053076561766,
      "grad_norm": 0.8899012804031372,
      "learning_rate": 0.0001899749373433584,
      "loss": 2.1188,
      "step": 40
    },
    {
      "epoch": 0.18788163457022075,
      "grad_norm": 0.944923996925354,
      "learning_rate": 0.00018746867167919798,
      "loss": 2.0339,
      "step": 50
    },
    {
      "epoch": 0.22545796148426492,
      "grad_norm": 0.894982635974884,
      "learning_rate": 0.0001849624060150376,
      "loss": 2.0242,
      "step": 60
    },
    {
      "epoch": 0.26303428839830906,
      "grad_norm": 0.837739109992981,
      "learning_rate": 0.0001824561403508772,
      "loss": 2.0458,
      "step": 70
    },
    {
      "epoch": 0.3006106153123532,
      "grad_norm": 0.8312574625015259,
      "learning_rate": 0.0001799498746867168,
      "loss": 1.9729,
      "step": 80
    },
    {
      "epoch": 0.3381869422263974,
      "grad_norm": 0.9990575909614563,
      "learning_rate": 0.0001774436090225564,
      "loss": 2.0168,
      "step": 90
    },
    {
      "epoch": 0.3757632691404415,
      "grad_norm": 0.9243261218070984,
      "learning_rate": 0.000174937343358396,
      "loss": 1.9409,
      "step": 100
    },
    {
      "epoch": 0.41333959605448567,
      "grad_norm": 0.76750248670578,
      "learning_rate": 0.00017243107769423558,
      "loss": 2.0509,
      "step": 110
    },
    {
      "epoch": 0.45091592296852984,
      "grad_norm": 0.9303663969039917,
      "learning_rate": 0.0001699248120300752,
      "loss": 1.9823,
      "step": 120
    },
    {
      "epoch": 0.488492249882574,
      "grad_norm": 0.7758277058601379,
      "learning_rate": 0.0001674185463659148,
      "loss": 1.9503,
      "step": 130
    },
    {
      "epoch": 0.5260685767966181,
      "grad_norm": 0.6893158555030823,
      "learning_rate": 0.0001649122807017544,
      "loss": 1.9802,
      "step": 140
    },
    {
      "epoch": 0.5636449037106623,
      "grad_norm": 2.186236619949341,
      "learning_rate": 0.00016240601503759398,
      "loss": 1.982,
      "step": 150
    },
    {
      "epoch": 0.6012212306247064,
      "grad_norm": 0.896066427230835,
      "learning_rate": 0.00015989974937343358,
      "loss": 2.0235,
      "step": 160
    },
    {
      "epoch": 0.6387975575387506,
      "grad_norm": 0.7657425999641418,
      "learning_rate": 0.00015739348370927319,
      "loss": 2.0304,
      "step": 170
    },
    {
      "epoch": 0.6763738844527948,
      "grad_norm": 0.7727847695350647,
      "learning_rate": 0.0001548872180451128,
      "loss": 1.9876,
      "step": 180
    },
    {
      "epoch": 0.7139502113668389,
      "grad_norm": 0.8622286915779114,
      "learning_rate": 0.00015238095238095237,
      "loss": 1.9738,
      "step": 190
    },
    {
      "epoch": 0.751526538280883,
      "grad_norm": 0.8212143778800964,
      "learning_rate": 0.000149874686716792,
      "loss": 1.9161,
      "step": 200
    },
    {
      "epoch": 0.7891028651949272,
      "grad_norm": 0.9037902355194092,
      "learning_rate": 0.00014736842105263158,
      "loss": 1.922,
      "step": 210
    },
    {
      "epoch": 0.8266791921089713,
      "grad_norm": 0.8599250316619873,
      "learning_rate": 0.00014486215538847118,
      "loss": 1.8825,
      "step": 220
    },
    {
      "epoch": 0.8642555190230155,
      "grad_norm": 0.8554670810699463,
      "learning_rate": 0.0001423558897243108,
      "loss": 1.9295,
      "step": 230
    },
    {
      "epoch": 0.9018318459370597,
      "grad_norm": 0.8806191086769104,
      "learning_rate": 0.0001398496240601504,
      "loss": 1.971,
      "step": 240
    },
    {
      "epoch": 0.9394081728511038,
      "grad_norm": 0.888205349445343,
      "learning_rate": 0.00013734335839598997,
      "loss": 1.8958,
      "step": 250
    },
    {
      "epoch": 0.976984499765148,
      "grad_norm": 0.9062823057174683,
      "learning_rate": 0.00013483709273182958,
      "loss": 1.9453,
      "step": 260
    },
    {
      "epoch": 1.0112728980742132,
      "grad_norm": 1.011728048324585,
      "learning_rate": 0.00013233082706766918,
      "loss": 1.9295,
      "step": 270
    },
    {
      "epoch": 1.0488492249882575,
      "grad_norm": 0.9658676981925964,
      "learning_rate": 0.0001298245614035088,
      "loss": 1.838,
      "step": 280
    },
    {
      "epoch": 1.0864255519023016,
      "grad_norm": 0.9623739123344421,
      "learning_rate": 0.00012731829573934836,
      "loss": 1.8764,
      "step": 290
    },
    {
      "epoch": 1.1240018788163457,
      "grad_norm": 0.9914631843566895,
      "learning_rate": 0.00012481203007518797,
      "loss": 1.8351,
      "step": 300
    },
    {
      "epoch": 1.1615782057303898,
      "grad_norm": 0.966228723526001,
      "learning_rate": 0.00012230576441102757,
      "loss": 1.8213,
      "step": 310
    },
    {
      "epoch": 1.199154532644434,
      "grad_norm": 0.9694830179214478,
      "learning_rate": 0.00011979949874686718,
      "loss": 1.8118,
      "step": 320
    },
    {
      "epoch": 1.2367308595584783,
      "grad_norm": 1.01338529586792,
      "learning_rate": 0.00011729323308270677,
      "loss": 1.8671,
      "step": 330
    },
    {
      "epoch": 1.2743071864725224,
      "grad_norm": 1.1398414373397827,
      "learning_rate": 0.00011478696741854638,
      "loss": 1.8444,
      "step": 340
    },
    {
      "epoch": 1.3118835133865665,
      "grad_norm": 1.1184577941894531,
      "learning_rate": 0.00011228070175438597,
      "loss": 1.8622,
      "step": 350
    },
    {
      "epoch": 1.3494598403006106,
      "grad_norm": 1.1013846397399902,
      "learning_rate": 0.00010977443609022557,
      "loss": 1.7663,
      "step": 360
    },
    {
      "epoch": 1.3870361672146547,
      "grad_norm": 1.1191530227661133,
      "learning_rate": 0.00010726817042606516,
      "loss": 1.8576,
      "step": 370
    },
    {
      "epoch": 1.424612494128699,
      "grad_norm": 1.1802330017089844,
      "learning_rate": 0.00010476190476190477,
      "loss": 1.837,
      "step": 380
    },
    {
      "epoch": 1.462188821042743,
      "grad_norm": 1.2604907751083374,
      "learning_rate": 0.00010225563909774436,
      "loss": 1.8028,
      "step": 390
    },
    {
      "epoch": 1.4997651479567873,
      "grad_norm": 1.0656781196594238,
      "learning_rate": 9.974937343358397e-05,
      "loss": 1.7767,
      "step": 400
    },
    {
      "epoch": 1.5373414748708314,
      "grad_norm": 1.0484089851379395,
      "learning_rate": 9.724310776942356e-05,
      "loss": 1.903,
      "step": 410
    },
    {
      "epoch": 1.5749178017848755,
      "grad_norm": 1.3620234727859497,
      "learning_rate": 9.473684210526316e-05,
      "loss": 1.8044,
      "step": 420
    },
    {
      "epoch": 1.6124941286989198,
      "grad_norm": 1.0188289880752563,
      "learning_rate": 9.223057644110275e-05,
      "loss": 1.8723,
      "step": 430
    },
    {
      "epoch": 1.6500704556129637,
      "grad_norm": 1.413880467414856,
      "learning_rate": 8.972431077694236e-05,
      "loss": 1.7667,
      "step": 440
    },
    {
      "epoch": 1.687646782527008,
      "grad_norm": 1.1887848377227783,
      "learning_rate": 8.721804511278195e-05,
      "loss": 1.7909,
      "step": 450
    },
    {
      "epoch": 1.7252231094410522,
      "grad_norm": 1.0809969902038574,
      "learning_rate": 8.471177944862155e-05,
      "loss": 1.7617,
      "step": 460
    },
    {
      "epoch": 1.7627994363550963,
      "grad_norm": 1.2188652753829956,
      "learning_rate": 8.220551378446115e-05,
      "loss": 1.7881,
      "step": 470
    },
    {
      "epoch": 1.8003757632691404,
      "grad_norm": 1.258968472480774,
      "learning_rate": 7.969924812030075e-05,
      "loss": 1.8002,
      "step": 480
    },
    {
      "epoch": 1.8379520901831845,
      "grad_norm": 1.2400072813034058,
      "learning_rate": 7.719298245614036e-05,
      "loss": 1.7943,
      "step": 490
    },
    {
      "epoch": 1.8755284170972288,
      "grad_norm": 1.1916605234146118,
      "learning_rate": 7.468671679197995e-05,
      "loss": 1.8102,
      "step": 500
    },
    {
      "epoch": 1.913104744011273,
      "grad_norm": 1.335076093673706,
      "learning_rate": 7.218045112781955e-05,
      "loss": 1.7759,
      "step": 510
    },
    {
      "epoch": 1.950681070925317,
      "grad_norm": 1.1425879001617432,
      "learning_rate": 6.967418546365914e-05,
      "loss": 1.7753,
      "step": 520
    },
    {
      "epoch": 1.9882573978393612,
      "grad_norm": 1.2495818138122559,
      "learning_rate": 6.716791979949875e-05,
      "loss": 1.7655,
      "step": 530
    },
    {
      "epoch": 2.0225457961484263,
      "grad_norm": 1.2310909032821655,
      "learning_rate": 6.49122807017544e-05,
      "loss": 1.7887,
      "step": 540
    },
    {
      "epoch": 2.0601221230624707,
      "grad_norm": 1.3420780897140503,
      "learning_rate": 6.240601503759398e-05,
      "loss": 1.6585,
      "step": 550
    },
    {
      "epoch": 2.097698449976515,
      "grad_norm": 1.3015258312225342,
      "learning_rate": 5.989974937343359e-05,
      "loss": 1.7192,
      "step": 560
    },
    {
      "epoch": 2.135274776890559,
      "grad_norm": 1.3473260402679443,
      "learning_rate": 5.739348370927319e-05,
      "loss": 1.7595,
      "step": 570
    },
    {
      "epoch": 2.1728511038046032,
      "grad_norm": 1.28394615650177,
      "learning_rate": 5.4887218045112786e-05,
      "loss": 1.7484,
      "step": 580
    },
    {
      "epoch": 2.210427430718647,
      "grad_norm": 1.2449547052383423,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 1.7149,
      "step": 590
    },
    {
      "epoch": 2.2480037576326914,
      "grad_norm": 1.2541754245758057,
      "learning_rate": 4.987468671679198e-05,
      "loss": 1.7478,
      "step": 600
    }
  ],
  "logging_steps": 10,
  "max_steps": 798,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8601546533437440.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
